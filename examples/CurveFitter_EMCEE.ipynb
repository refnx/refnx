{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of MCMC non-linear regression with EMCEE and refnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`refnx` is a package that can be used for non-linear regression (curvefitting). Here I demonstrate how it can be used to analyse Gaussian curve dataset, with Bayesian MCMC sampling of the posterior distributions of the parameters. This is a very robust way of estimating parameter uncertainties. I will also do the analysis with the `emcee` package for comparison\n",
    "\n",
    "The first step is all the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import corner\n",
    "from scipy.optimize import leastsq\n",
    "from refnx.analysis import CurveFitter, Parameter, Parameters, Model, Objective\n",
    "from refnx.dataset import Data1D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to load some data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data1D('gauss_data.txt')\n",
    "plt.errorbar(data.x, data.y, yerr=data.y_err, fmt='.k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, p, *args):\n",
    "    # p is a Parameters instance. A quick way of getting all the numerical values out\n",
    "    # is making it into array. However, there alternate ways of access:\n",
    "    # e.g. p['bkg'].value or p[0].value.\n",
    "    p0 = np.array(p)\n",
    "    return p0[0] + p0[1] * np.exp(-((x - p0[2]) / p0[3])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up initial parameter guesses and lower and upper bounds. The last step is to create a `refnx.Parameters` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bkg = Parameter(0.1, 'bkg', vary=True, bounds=(-1, 1))\n",
    "amp = Parameter(20, 'amp', vary=True, bounds=(0, 30))\n",
    "mu = Parameter(0.1, 'mu', vary=True, bounds=(-5, 5))\n",
    "wid = Parameter(0.1, 'wid', vary=True, bounds=(0.001, 2))\n",
    "\n",
    "# to get numerical values out of p0 you have to use np.array(p0), or refer to each Parameter\n",
    "# by using p0['bkg'].value or p0[0].value.\n",
    "p0 = bkg | amp | mu | wid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse with emcee\n",
    "\n",
    "To start with we'll do the analysis with the `emcee` package. Then we'll repeat the analysis with `refnx.analysis.CurveFitter`. \n",
    "\n",
    "The following functions have to be defined for `emcee`. The log-likelihood, the uniform log-prior and the overall log-posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounds_varying = np.array([[-1, 0, -5, 0.001], [1, 30, 5, 2]]).T\n",
    "\n",
    "def residuals(theta):\n",
    "    resid = (gauss(data.x, theta) - data.y) / data.y_err\n",
    "    return resid\n",
    "    \n",
    "def lnlike(theta):\n",
    "    # log likelihood\n",
    "    return -0.5 * (np.sum(residuals(theta) ** 2))\n",
    "\n",
    "def lnprior(theta):\n",
    "    # uniform prior\n",
    "    if (np.any(theta > bounds_varying[:, 1])\n",
    "            or np.any(theta < bounds_varying[:, 0])):\n",
    "        return -np.inf\n",
    "    return 0\n",
    "\n",
    "def lnpost(theta):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fit the data with least squares first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = leastsq(residuals, p0, full_output=True)\n",
    "best_fit = result[0]\n",
    "best_errors = np.sqrt(np.diag(result[1]))\n",
    "for mean, std in zip(best_fit, best_errors):\n",
    "    print(\"{:<12g} +/-  {:<10g}\".format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the walkers for `emcee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndim, nwalkers = 4, 100\n",
    "pos = np.array([np.array(p0) * (1 + 1e-2 * np.random.randn(ndim))\n",
    "                for i in range(nwalkers)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `emcee` sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnpost)\n",
    "a = sampler.run_mcmc(pos, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard 100 burn in steps for each walker and flatten the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chain = sampler.chain[:, 100:, :].reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse with CurveFitter\n",
    "\n",
    "Now we're going to do the analysis using a `refnx.analysis.CurveFitter` instance, it should be a lot simpler than the direct approach above. First setup the curvefitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first setup a model\n",
    "model = Model(p0, fitfunc=gauss)\n",
    "\n",
    "# an objective is composed of a model and data\n",
    "objective = Objective(model, data)\n",
    "\n",
    "# a fitter is constructed\n",
    "fitter = CurveFitter(objective, nwalkers=100, threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all do a least-squares fit, to get a starting point for the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_leastsq = fitter.fit('least_squares')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the MCMC sampling with CurveFitter instead. There are 100 walkers, we do 1000 steps on each walker. After the sampling discard the first 100 steps of each walker and take every 5th step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.sample(1000)\n",
    "res_sampling = fitter.process_chain(nburn=100, nthin=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the posterior distributions for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = corner.corner(fitter.sampler.flatchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the fits, are they good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(data.x, data.y, yerr=data.y_err, fmt=\".\")\n",
    "\n",
    "saved_state = np.array(p0)\n",
    "# plot a selection of the samples\n",
    "for pars in objective.pgen(500):\n",
    "    # could also use:\n",
    "    # >>> objective.setp(pars)\n",
    "    # then to calculate the model:\n",
    "    # >>> model(data.x)\n",
    "    plt.plot(data.x, objective.generative(pars), color=\"k\", alpha=0.02)\n",
    "\n",
    "plt.plot(data.x, gauss(data.x, p0), color='r', label='sampling')\n",
    "objective.setp(saved_state)\n",
    "\n",
    "# the leastsq fit overlies the sampling\n",
    "# plt.plot(data.x, gauss(data.x, best_fit), color='g', label='leastsq')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fit parameters are obtained. Lets compare them to the least squares output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Curvefitter.sampling\")\n",
    "print(objective)\n",
    "\n",
    "print(\"\\nleastsq\")\n",
    "print(\"-------\")\n",
    "print(best_fit, '\\n', best_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
